{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a976a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('brain-tumor-mri-dataset'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "423838f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Flatten,Dense,MaxPooling2D,Dropout\n",
    "from keras import backend as K\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e8885e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5712, 75, 75, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "image_size = 75\n",
    "train_folder_path = 'brain-tumor-mri-dataset/Training'\n",
    "test_folder_path = 'brain-tumor-mri-dataset/Testing'\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for i, label in enumerate(labels):\n",
    "    folder_path = os.path.join(train_folder_path, label)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        train_images.append(img)\n",
    "        train_labels.append(i)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i, label in enumerate(labels):\n",
    "    folder_path = os.path.join(test_folder_path, label)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        test_images.append(img)\n",
    "        test_labels.append(i)\n",
    "\n",
    "X_train = np.array(train_images)\n",
    "Y_train = np.array(train_labels)\n",
    "X_test = np.array(test_images)\n",
    "Y_test = np.array(test_labels)\n",
    "\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "    \n",
    "X_train,Y_train = shuffle(X_train,Y_train,random_state=101)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18aa791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'brain-tumor-mri-dataset/Training'\n",
    "test_dir = 'brain-tumor-mri-dataset/Testing'\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "168213ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_train,Y_train,test_size=0.1,random_state=101)\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, num_classes = len(labels))\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, num_classes = len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fd54d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='softmax', input_shape=(75, 75, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "495740e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 73, 73, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 73, 73, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 34, 34, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36992)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               18940416  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 19,018,884\n",
      "Trainable params: 19,018,500\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ea1fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "from keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = K.round(y_true)\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum ((1-y_true) * y_pred)\n",
    "    fn = K.sum(y_true * (1-y_pred))\n",
    "    precison = tp / (tp + fn + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1_score = 2*((precison*recall)/ (precison+recall+K.epsilon()))\n",
    "    return f1_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor= 'val_loss', patience = 3)\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(loss= 'categorical_crossentropy',optimizer= RMSprop(learning_rate= 0.001),metrics=['accuracy', f1_score, Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87fdaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('projectbraintumor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "212e983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "73/73 [==============================] - 8s 86ms/step - loss: 11.2591 - accuracy: 0.6866 - f1_score: 0.6404 - precision_6: 0.7168 - recall_6: 0.6379 - val_loss: 43.6010 - val_accuracy: 0.2432 - val_f1_score: 0.2170 - val_precision_6: 0.2432 - val_recall_6: 0.2432\n",
      "Epoch 2/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.6596 - accuracy: 0.8087 - f1_score: 0.7913 - precision_6: 0.8240 - recall_6: 0.7903 - val_loss: 79.1091 - val_accuracy: 0.2432 - val_f1_score: 0.2170 - val_precision_6: 0.2432 - val_recall_6: 0.2432\n",
      "Epoch 3/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.4046 - accuracy: 0.8805 - f1_score: 0.8698 - precision_6: 0.8896 - recall_6: 0.8707 - val_loss: 103.3581 - val_accuracy: 0.2432 - val_f1_score: 0.2170 - val_precision_6: 0.2432 - val_recall_6: 0.2432\n",
      "Epoch 4/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.2902 - accuracy: 0.9034 - f1_score: 0.9001 - precision_6: 0.9079 - recall_6: 0.8997 - val_loss: 28.7840 - val_accuracy: 0.2549 - val_f1_score: 0.2257 - val_precision_6: 0.2539 - val_recall_6: 0.2529\n",
      "Epoch 5/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.1991 - accuracy: 0.9308 - f1_score: 0.9275 - precision_6: 0.9340 - recall_6: 0.9274 - val_loss: 3.7866 - val_accuracy: 0.5078 - val_f1_score: 0.4948 - val_precision_6: 0.5184 - val_recall_6: 0.4942\n",
      "Epoch 6/20\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9442 - f1_score: 0.9427 - precision_6: 0.9464 - recall_6: 0.94 - 6s 78ms/step - loss: 0.1655 - accuracy: 0.9442 - f1_score: 0.9427 - precision_6: 0.9464 - recall_6: 0.9427 - val_loss: 1.5445 - val_accuracy: 0.6518 - val_f1_score: 0.6267 - val_precision_6: 0.6640 - val_recall_6: 0.6420\n",
      "Epoch 7/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.1200 - accuracy: 0.9587 - f1_score: 0.9591 - precision_6: 0.9600 - recall_6: 0.9587 - val_loss: 0.3796 - val_accuracy: 0.8988 - val_f1_score: 0.9062 - val_precision_6: 0.9020 - val_recall_6: 0.8949\n",
      "Epoch 8/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0871 - accuracy: 0.9764 - f1_score: 0.9762 - precision_6: 0.9766 - recall_6: 0.9760 - val_loss: 0.3892 - val_accuracy: 0.9105 - val_f1_score: 0.9184 - val_precision_6: 0.9121 - val_recall_6: 0.9086\n",
      "Epoch 9/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0720 - accuracy: 0.9795 - f1_score: 0.9795 - precision_6: 0.9795 - recall_6: 0.9792 - val_loss: 0.4533 - val_accuracy: 0.9222 - val_f1_score: 0.9306 - val_precision_6: 0.9240 - val_recall_6: 0.9222\n",
      "Epoch 10/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0644 - accuracy: 0.9814 - f1_score: 0.9810 - precision_6: 0.9816 - recall_6: 0.9814 - val_loss: 0.7468 - val_accuracy: 0.9105 - val_f1_score: 0.9184 - val_precision_6: 0.9103 - val_recall_6: 0.9086\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size = 64, epochs= 20, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "image_size = 75\n",
    "train_folder_path = 'brain-tumor-mri-dataset/Training'\n",
    "test_folder_path = 'brain-tumor-mri-dataset/Testing'\n",
    "\n",
    "# Load the training dataset\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for i, label in enumerate(labels):\n",
    "    folder_path = os.path.join(train_folder_path, label)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        train_images.append(img)\n",
    "        train_labels.append(i)\n",
    "\n",
    "# Load the test dataset for use in model.evaluate\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i, label in enumerate(labels):\n",
    "    folder_path = os.path.join(test_folder_path, label)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        test_images.append(img)\n",
    "        test_labels.append(i)\n",
    "\n",
    "# Convert the image data and label arrays to NumPy arrays\n",
    "X_train = np.array(train_images)\n",
    "Y_train = np.array(train_labels)\n",
    "X_test = np.array(test_images)\n",
    "Y_test = np.array(test_labels)\n",
    "\n",
    "# Convert the label arrays to integers\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "    \n",
    "#shuffle training dataset\n",
    "X_train,Y_train = shuffle(X_train,Y_train,random_state=101)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Y_true = test_generator.classes\n",
    "Y_pred = model.predict(X_test)\n",
    "predicted_labels = np.argmax(Y_pred, axis=-1)\n",
    "\n",
    "print(classification_report(Y_true, predicted_labels, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc)) # def range of vakues for x-axis as number of epochs\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, acc,'r',label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc,'b',label=\"Validation Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('Graphs of Training and Validation Accuracy.png') # to download img\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(loss))\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs,loss,'r',label=\"Training loss\")\n",
    "plt.plot(epochs,val_loss,'b',label=\"Validation loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.savefig('Graphs of Training and Validation Loss.png') # to download img\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('brain-tumor-mri-dataset/Testing/pituitary/Te-piTr_0000.jpg')\n",
    "img = cv2.resize(img,(75,75))\n",
    "img_array = np.array(img)\n",
    "img_array.shape\n",
    "\n",
    "img_array = img_array.reshape(1,75,75,3)\n",
    "img_array.shape\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "img = image.load_img('brain-tumor-mri-dataset/Testing/pituitary/Te-piTr_0000.jpg')\n",
    "plt.imshow(img,interpolation='nearest')\n",
    "plt.savefig('Pituitary.png') # to download img\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.predict(img_array)\n",
    "indices = a.argmax()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dataset = np.random.randint(0, 10, size=(7022, 2))  \n",
    "labels = np.random.randint(0, 4, size=(7022,))  \n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "class_samples = defaultdict(list)\n",
    "for i, label in enumerate(labels):\n",
    "    class_samples[label].append(dataset[i])\n",
    "\n",
    "train_set = []\n",
    "test_set = []\n",
    "val_set = []\n",
    "\n",
    "for class_label, samples in class_samples.items():\n",
    "    num_samples = len(samples)\n",
    "    num_train_samples = int(num_samples * train_ratio)\n",
    "    num_test_samples = int(num_samples * test_ratio)\n",
    "    num_val_samples = num_samples - num_train_samples - num_test_samples\n",
    "\n",
    "    np.random.seed(101)  \n",
    "    \n",
    "    train_set.extend(samples[:num_train_samples])\n",
    "    test_set.extend(samples[num_train_samples:num_train_samples+num_test_samples])\n",
    "    val_set.extend(samples[num_train_samples+num_test_samples:])\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "test_set = np.array(test_set)\n",
    "val_set = np.array(val_set)\n",
    "\n",
    "for class_label, samples in class_samples.items():\n",
    "    num_train_samples = int(len(samples) * train_ratio)\n",
    "    num_test_samples = int(len(samples) * test_ratio)\n",
    "    num_val_samples = len(samples) - num_train_samples - num_test_samples\n",
    "\n",
    "    print(\"Class Label:\", class_label)\n",
    "    print(\"Number of samples in train set:\", num_train_samples)\n",
    "    print(\"Number of samples in test set:\", num_test_samples)\n",
    "    print(\"Number of samples in validation set:\", num_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d996358",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1621, 1645, 2000, 1757] \n",
    "total = sum(numbers)\n",
    "percent = [(num /total) * 100 for num in numbers]\n",
    "colors = ['#99c2ff', '#6699ff', '#3377ff', '#0052cc']\n",
    "labels=['Glioma tumor','Meningioma tumor', 'No tumor', 'Pituitary tumor'] #needed cus labels is defined again below but with diff elements\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(percent, colors = colors, labels = labels, autopct = '%1.1f%%', startangle = 90)\n",
    "ax1.axis('equal')\n",
    "plt.title(\"Class Distribution of the Dataset\")\n",
    "plt.savefig('Class Distribution of the Dataset.png') # to download img\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 5712\n",
    "test = 1311\n",
    "total = train + test\n",
    "train_percent = (train / total) * 100\n",
    "test_percent = (test / total) * 100\n",
    "labels = ['Training', 'Testing']\n",
    "percent = [train_percent, test_percent]\n",
    "colors = ['#3377ff', '#cc6666']\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(percent, colors=colors, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title(\"Distribution of Images in the Training and Testing Folders\")\n",
    "plt.savefig('Distribution of Images in the Training and Testing Folders.png') # to download img\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_labels = test_generator.classes\n",
    "y_pred = model.predict(X_test)\n",
    "predicted_labels = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "print(\"Shape of true_labels:\", true_labels.shape)\n",
    "print(\"Data type of true_labels:\", true_labels.dtype)\n",
    "print(\"Shape of predicted_labels:\", predicted_labels.shape)\n",
    "print(\"Data type of predicted_labels:\", predicted_labels.dtype)\n",
    "\n",
    "labels = ['Glioma tumor', 'Meningioma tumor', 'No tumor', 'Pituitary tumor']\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=np.arange(len(labels)) + 0.5, labels=labels)\n",
    "plt.yticks(rotation=0, ticks=np.arange(len(labels)) + 0.5, labels=labels)\n",
    "plt.savefig('Confusion Matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f59061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
